# generate/STEP3_generate_camouflage_bot.py (v2 - with Quantity Control)
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import os
import joblib
from config import UNIFIED_FEATURE_SET, TARGET_FIELDS_FOR_LSTM


# --- 1. æ¨¡åž‹å®šä¹‰ ---
class ConditionalAE(nn.Module):
    def __init__(self, input_dim, condition_dim, encoding_dim):
        super().__init__();
        self.encoder = nn.Sequential(nn.Linear(input_dim + condition_dim, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(),
                                     nn.Linear(16, encoding_dim));
        self.decoder = nn.Sequential(nn.Linear(encoding_dim + condition_dim, 16), nn.ReLU(), nn.Linear(16, 32),
                                     nn.ReLU(), nn.Linear(32, input_dim))

    def forward(self, x, c):
        x_cond = torch.cat([x, c], dim=1);
        encoded = self.encoder(x_cond);
        return encoded


class PredictiveLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__();
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, num_layers=2, dropout=0.2);
        self.fc = nn.Sequential(nn.Linear(hidden_dim, 32), nn.ReLU(), nn.Dropout(0.2), nn.Linear(32, output_dim))

    def forward(self, x):
        lstm_out, _ = self.lstm(x);
        last_time_step_out = lstm_out[:, -1, :];
        return self.fc(last_time_step_out)


# --- 2. é…ç½®åŒº ---
DATA_DIR_PREPROCESSED = r'D:\DTCA\data\preprocessed'
DATA_DIR_FILTERED = r'D:\DTCA\data\filtered'
DATA_DIR_GENERATED = r'D:\DTCA\data\generated'
MODELS_DIR = r'D:\DTCA\models'
os.makedirs(DATA_DIR_GENERATED, exist_ok=True)

cae_model_path = os.path.join(MODELS_DIR, 'style_transfer_cae.pt')
lstm_model_path = os.path.join(MODELS_DIR, 'bot_pattern_lstm.pt')
benign_processed_path = os.path.join(DATA_DIR_PREPROCESSED, 'benign_traffic_processed.csv')
raw_benign_csv_path = os.path.join(DATA_DIR_FILTERED, 'benign_traffic.csv')
target_scaler_path = os.path.join(MODELS_DIR, 'target_scaler_bot.pkl')
output_csv_path = os.path.join(DATA_DIR_GENERATED, 'final_camouflage_bot.csv')

# âœ… æ ¸å¿ƒä¿®æ”¹ï¼šå®šä¹‰æˆ‘ä»¬æƒ³è¦ç”Ÿæˆçš„ä¼ªè£…Botæ•°é‡
NUM_TO_GENERATE = 30000  # ç”Ÿæˆ4ä¸‡æ¡ï¼Œå¤§çº¦æ˜¯çœŸå®žBotæ•°é‡çš„100å€

input_dim_cae = len(UNIFIED_FEATURE_SET);
encoding_dim = 5;
condition_dim = 2
input_dim_lstm = encoding_dim;
hidden_dim_lstm = 64;
output_dim_lstm = len(TARGET_FIELDS_FOR_LSTM)
window_size = 3
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# --- 3. ä¸»ç”Ÿæˆå‡½æ•° ---
def main():
    print("=============================================");
    print("ðŸš€ STEP 3: å¼€å§‹æ‰§è¡Œ'è‰¯æ€§å˜å½¢è®°'ï¼Œç”Ÿæˆæœ€ç»ˆä¼ªè£…Botæµé‡...");
    print("=============================================")

    # 1. åŠ è½½æ‰€æœ‰æ ¸å¿ƒå¼•æ“Žå’Œæ•°æ®
    print("æ­£åœ¨åŠ è½½æ‰€æœ‰æ¨¡åž‹ã€scalerå’ŒåŽŸææ–™...");
    cae_model = ConditionalAE(input_dim_cae, condition_dim, encoding_dim).to(device)
    cae_model.load_state_dict(torch.load(cae_model_path));
    cae_model.eval()
    lstm_model = PredictiveLSTM(input_dim_lstm, hidden_dim_lstm, output_dim_lstm).to(device)
    lstm_model.load_state_dict(torch.load(lstm_model_path));
    lstm_model.eval()
    target_scaler = joblib.load(target_scaler_path)

    # âœ… æ ¸å¿ƒä¿®æ”¹ï¼šåªåŠ è½½æˆ‘ä»¬éœ€è¦æ•°é‡çš„â€œåŽŸææ–™â€ï¼ˆè‰¯æ€§æµé‡ï¼‰
    df_benign_processed = pd.read_csv(benign_processed_path, nrows=NUM_TO_GENERATE + window_size)
    df_benign_raw = pd.read_csv(raw_benign_csv_path, nrows=NUM_TO_GENERATE + window_size)
    df_benign_raw.columns = df_benign_raw.columns.str.strip()
    print(f"  -> å·²åŠ è½½ {len(df_benign_raw)} æ¡è‰¯æ€§æµé‡ä½œä¸ºç”ŸæˆåŽŸææ–™ã€‚")

    # 2. é™æ€é£Žæ ¼è¿ç§»
    print("\n[ç¬¬ä¸€é˜¶æ®µ] æ­£åœ¨è¿›è¡Œé™æ€é£Žæ ¼è¿ç§»...");
    X_benign_tensor = torch.tensor(df_benign_processed.values, dtype=torch.float32).to(device)
    C_bot_label = torch.zeros(len(X_benign_tensor), condition_dim).to(device);
    C_bot_label[:, 1] = 1
    with torch.no_grad():
        z_fake_bot = cae_model(X_benign_tensor, C_bot_label).cpu().numpy()

    # 3. åŠ¨æ€æ¨¡å¼æ³¨å…¥
    print("\n[ç¬¬äºŒé˜¶æ®µ] æ­£åœ¨è¿›è¡ŒåŠ¨æ€æ¨¡å¼æ³¨å…¥...");
    X_seq, pred_indices = [], []
    for i in range(len(z_fake_bot) - window_size):
        X_seq.append(z_fake_bot[i:i + window_size]);
        pred_indices.append(i + window_size - 1)
    with torch.no_grad():
        predictions_scaled = lstm_model(torch.tensor(np.array(X_seq), dtype=torch.float32).to(device)).cpu().numpy()
    predictions_real = target_scaler.inverse_transform(predictions_scaled)

    # 4. åº”ç”¨çº¦æŸå¹¶ç”Ÿæˆ
    print("\n[ç¬¬ä¸‰é˜¶æ®µ] æ­£åœ¨åº”ç”¨çº¦æŸå¹¶ç»„è£…æœ€ç»ˆä¼ªè£…Bot...");
    df_camouflage = df_benign_raw.copy()
    df_bot_raw = pd.read_csv(os.path.join(DATA_DIR_FILTERED, 'bot_traffic_target.csv'))
    df_bot_raw.columns = df_bot_raw.columns.str.strip()
    upper_bounds = df_bot_raw[TARGET_FIELDS_FOR_LSTM].quantile(0.95).values
    lower_bounds = df_bot_raw[TARGET_FIELDS_FOR_LSTM].quantile(0.05).values
    original_values_to_modify = df_camouflage.loc[pred_indices, TARGET_FIELDS_FOR_LSTM].values
    modified_values = np.where(
        (predictions_real >= lower_bounds) & (predictions_real <= upper_bounds),
        predictions_real,
        original_values_to_modify
    )
    df_camouflage.loc[pred_indices, TARGET_FIELDS_FOR_LSTM] = modified_values
    final_camouflage_df = df_camouflage.iloc[pred_indices].copy()

    # 5. ä¿å­˜æœ€ç»ˆæˆæžœ
    final_camouflage_df = final_camouflage_df[UNIFIED_FEATURE_SET]
    final_camouflage_df.to_csv(output_csv_path, index=False)

    print("\n=============================================");
    print(f"ðŸŽ‰ æ­å–œï¼'è‰¯æ€§å˜å½¢è®°'å®Œæˆï¼");
    print(f"âœ… æœ€ç»ˆçš„ä¼ªè£…Botæµé‡å·²ä¿å­˜è‡³: {output_csv_path}");
    print(f"   å…±ç”Ÿæˆ {len(final_camouflage_df)} æ¡é«˜ä¿çœŸä¼ªè£…Botæµé‡ã€‚");
    print("=============================================")


if __name__ == "__main__":
    main()