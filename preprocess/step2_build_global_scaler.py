# preprocess/step2_build_global_scaler.py
import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import MinMaxScaler
import joblib
from config import UNIFIED_FEATURE_SET # å¯¼å…¥æˆ‘ä»¬æœ€ç»ˆçš„ç»Ÿä¸€ç‰¹å¾é›†

# ==========================================================
# --- 1. é…ç½®åŒº ---
# ==========================================================
# è¾“å…¥: æˆ‘ä»¬çš„åŸºç¡€å‚ç…§ç³»â€”â€”çº¯è‰¯æ€§æµé‡
input_path = r'D:\DTCA\data\filtered\benign_traffic.csv'

# è¾“å‡º
output_dir = r'D:\DTCA\data\preprocessed'
output_csv_path = os.path.join(output_dir, 'benign_traffic_processed.csv')
# âœ… æ ¸å¿ƒè¾“å‡ºï¼šæˆ‘ä»¬å”¯ä¸€çš„ã€å…¨å±€çš„â€œåº¦é‡è¡¡â€
scaler_path = os.path.join(r'D:\DTCA\models', 'global_scaler.pkl')

# ==========================================================
# --- 2. ä¸»å‡½æ•° ---
# ==========================================================
def main():
    print("=============================================")
    print("ğŸš€ STEP 2a: æ„å»ºå…¨å±€Scalerå¹¶å¤„ç†BENIGNæµé‡...")
    print("=============================================")

    print(f"æ­£åœ¨åŠ è½½è‰¯æ€§æµé‡æ•°æ®: {input_path}...")
    df = pd.read_csv(input_path, low_memory=False)
    df.columns = df.columns.str.strip()

    # --- 1. æ•°æ®éªŒè¯ä¸æ¸…ç† ---
    missing_features = [f for f in UNIFIED_FEATURE_SET if f not in df.columns]
    if missing_features:
        print(f"é”™è¯¯: åœ¨è‰¯æ€§æ•°æ®ä¸­æ‰¾ä¸åˆ°ä»¥ä¸‹ç‰¹å¾: {missing_features}"); return

    df_selected = df[UNIFIED_FEATURE_SET].copy()
    print(f"å·²é€‰æ‹© {len(df_selected.columns)} ä¸ªç»Ÿä¸€ç‰¹å¾ã€‚")

    df_selected.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_selected.dropna(inplace=True)
    print(f"æ•°æ®æ¸…ç†åï¼Œå‰©ä½™æ ·æœ¬æ•°: {len(df_selected)}")

    # --- 2. è®­ç»ƒå…¨å±€Scalerå¹¶å½’ä¸€åŒ– ---
    print("\næ­£åœ¨è®­ç»ƒå…¨å±€Scalerå¹¶å¯¹è‰¯æ€§æ•°æ®è¿›è¡Œå½’ä¸€åŒ–...")
    scaler = MinMaxScaler()
    # âœ… å…³é”®æ“ä½œ: åœ¨è‰¯æ€§æ•°æ®ä¸Š .fit_transform()
    features_scaled = scaler.fit_transform(df_selected)
    df_processed = pd.DataFrame(features_scaled, columns=UNIFIED_FEATURE_SET)

    # --- 3. ä¿å­˜ç»“æœ ---
    df_processed.to_csv(output_csv_path, index=False)
    print(f"âœ… å·²ä¿å­˜å¤„ç†åçš„è‰¯æ€§æµé‡æ•°æ®åˆ°: {output_csv_path}")

    joblib.dump(scaler, scaler_path)
    print(f"âœ… å…¨å±€Scalerå·²ä¿å­˜åˆ°: {scaler_path}")

if __name__ == "__main__":
    main()