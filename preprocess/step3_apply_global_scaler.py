# preprocess/step3_apply_global_scaler.py
import pandas as pd
import numpy as np
import os
import joblib
from config import UNIFIED_FEATURE_SET  # å¯¼å…¥æˆ‘ä»¬æœ€ç»ˆçš„ç»Ÿä¸€ç‰¹å¾é›†

# ==========================================================
# --- 1. é…ç½®åŒº ---
# ==========================================================
# è¾“å…¥:
# 1. å¾…å¤„ç†çš„æ•°æ® (Botæµé‡)
input_path = r'D:\DTCA\data\filtered\bot_traffic_target.csv'
# 2. æˆ‘ä»¬å”¯ä¸€çš„â€œåº¦é‡è¡¡â€
scaler_path = os.path.join(r'D:\DTCA\models', 'global_scaler.pkl')

# è¾“å‡º
output_dir = r'D:\DTCA\data\preprocessed'
output_csv_path = os.path.join(output_dir, 'bot_traffic_processed.csv')


# ==========================================================
# --- 2. ä¸»å‡½æ•° ---
# ==========================================================
def main():
    print("=============================================")
    print("ğŸš€ STEP 2b: åº”ç”¨å…¨å±€Scalerå¤„ç†BOTæµé‡...")
    print("=============================================")

    try:
        print(f"æ­£åœ¨åŠ è½½Botæµé‡æ•°æ®: {input_path}...")
        df = pd.read_csv(input_path, low_memory=False)
        print(f"æ­£åœ¨åŠ è½½å…¨å±€Scaler: {scaler_path}...")
        scaler = joblib.load(scaler_path)
    except FileNotFoundError as e:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ - {e}")
        print("è¯·ç¡®ä¿æ‚¨å·²ç»æˆåŠŸè¿è¡Œäº† 'step2_build_global_scaler.py'")
        return

    df.columns = df.columns.str.strip()

    # --- 1. æ•°æ®éªŒè¯ä¸æ¸…ç† ---
    missing_features = [f for f in UNIFIED_FEATURE_SET if f not in df.columns]
    if missing_features:
        print(f"é”™è¯¯: åœ¨Botæ•°æ®ä¸­æ‰¾ä¸åˆ°ä»¥ä¸‹ç‰¹å¾: {missing_features}");
        return

    df_selected = df[UNIFIED_FEATURE_SET].copy()
    df_selected.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_selected.dropna(inplace=True)
    print(f"æ•°æ®æ¸…ç†åï¼Œå‰©ä½™æ ·æœ¬æ•°: {len(df_selected)}")

    # --- 2. åº”ç”¨å…¨å±€Scaler ---
    print("\næ­£åœ¨ä½¿ç”¨å…¨å±€Scalerå¯¹Botæ•°æ®è¿›è¡Œå½’ä¸€åŒ–...")
    # âœ… å…³é”®æ“ä½œ: åªèƒ½ä½¿ç”¨ .transform()
    features_scaled = scaler.transform(df_selected)
    df_processed = pd.DataFrame(features_scaled, columns=UNIFIED_FEATURE_SET)

    # --- 3. ä¿å­˜ç»“æœ ---
    df_processed.to_csv(output_csv_path, index=False)
    print(f"âœ… å·²ä¿å­˜å¤„ç†åçš„Botæµé‡æ•°æ®åˆ°: {output_csv_path}")


if __name__ == "__main__":
    main()