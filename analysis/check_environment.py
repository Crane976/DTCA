import sys
import platform
import torch
import sklearn
import xgboost


def get_size(bytes, suffix="B"):
    """Scale bytes to its proper format"""
    factor = 1024
    for unit in ["", "K", "M", "G", "T", "P"]:
        if bytes < factor:
            return f"{bytes:.2f}{unit}{suffix}"
        bytes /= factor


def check_config():
    print("=" * 60)
    print("ðŸ–¥ï¸  å®žéªŒçŽ¯å¢ƒé…ç½®æ£€æµ‹æŠ¥å‘Š (Experimental Environment Report)")
    print("=" * 60)

    # --- 1. ç¡¬ä»¶ä¿¡æ¯ (Hardware) ---
    print("\n[Hardware Configuration]")
    # CPU
    print(f"CPU Processor: {platform.processor()}")
    # å†…å­˜ (RAM) - è¿™æ˜¯ä¸€ä¸ªä¼°ç®—ï¼Œå¦‚æžœä½ çŸ¥é“ç¡®åˆ‡çš„ç‰©ç†å†…å­˜æ¡å¤§å°(å¦‚16G, 32G)ï¼Œä»¥ç‰©ç†å†…å­˜ä¸ºå‡†
    try:
        import psutil
        ram = psutil.virtual_memory()
        print(f"System RAM:    {get_size(ram.total)}")
    except ImportError:
        print("System RAM:    (è¯·åœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­æŸ¥çœ‹ï¼Œä¾‹å¦‚ 16GB æˆ– 32GB)")

    # GPU
    if torch.cuda.is_available():
        print(f"GPU Model:     {torch.cuda.get_device_name(0)}")
        # VRAM
        vram_bytes = torch.cuda.get_device_properties(0).total_memory
        print(f"GPU VRAM:      {get_size(vram_bytes)}")
        print(f"CUDA Version:  {torch.version.cuda}")
    else:
        print("GPU:           None (Running on CPU)")

    # --- 2. è½¯ä»¶ä¿¡æ¯ (Software) ---
    print("\n[Software Configuration]")
    print(f"OS Platform:   {platform.system()} {platform.release()}")
    print(f"Python Ver:    {sys.version.split()[0]}")
    print(f"PyTorch Ver:   {torch.__version__}")
    print(f"Scikit-learn:  {sklearn.__version__}")
    print(f"XGBoost Ver:   {xgboost.__version__}")

    # IDE (IDEé€šå¸¸ä¸ç”¨ä»£ç æŸ¥ï¼Œä½ è‡ªå·±çŸ¥é“æ˜¯ PyCharm)
    print("IDE Platform:  PyCharm (Professional/Community)")


if __name__ == "__main__":
    check_config()