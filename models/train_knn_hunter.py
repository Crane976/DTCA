# models/train_knn_hunter.py (FINAL FIXED VERSION WITH DATA CLEANING)
import pandas as pd
import numpy as np
import os
import sys
import joblib
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path: sys.path.append(project_root)

from config import DEFENDER_SET, set_seed

try:
    plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['axes.unicode_minus'] = False
except Exception:
    pass

# --- é…ç½®åŒº ---
TRAIN_SET_PATH = os.path.join(project_root, 'data', 'splits', 'training_set.csv')
TEST_SET_PATH = os.path.join(project_root, 'data', 'splits', 'holdout_test_set.csv')
SCALER_PATH = os.path.join(project_root, 'models', 'global_scaler.pkl')
MODELS_DIR = os.path.join(project_root, 'models')
FIGURES_DIR = os.path.join(project_root, 'figures')
HUNTER_MODEL_PATH = os.path.join(MODELS_DIR, 'knn_hunter.pkl')


def main():
    set_seed(2025)
    print("=" * 60)
    print("ðŸš€ å¼€å§‹è®­ç»ƒ KNN Hunter (ä¿®å¤ç‰ˆ: å«æ•°æ®æ¸…æ´—)...")
    print("=" * 60)

    # --- 1. åŠ è½½æ•°æ® ---
    print("æ­£åœ¨åŠ è½½æ•°æ®...")
    try:
        df_train_full = pd.read_csv(TRAIN_SET_PATH)
        df_test = pd.read_csv(TEST_SET_PATH)
        scaler = joblib.load(SCALER_PATH)
        feature_names = scaler.feature_names_in_
    except FileNotFoundError as e:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ ¸å¿ƒæ–‡ä»¶ - {e}");
        return

    # --- âœ… å…³é”®ä¿®å¤: æ•°æ®æ¸…æ´— (ç›´æŽ¥ä¸¢å¼ƒ Inf/NaN) ---
    print("æ­£åœ¨æ¸…æ´—æ•°æ® (åŽ»é™¤ Inf/NaN)...")
    # 1. æ›¿æ¢ Inf
    df_train_full.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_test.replace([np.inf, -np.inf], np.nan, inplace=True)

    # 2. ä¸¢å¼ƒè„æ•°æ®
    len_before = len(df_train_full)
    df_train_full.dropna(subset=feature_names, inplace=True)
    print(f"   -> è®­ç»ƒé›†æ¸…æ´—æŽ‰ {len_before - len(df_train_full)} æ¡è„æ•°æ®")

    len_test_before = len(df_test)
    df_test.dropna(subset=feature_names, inplace=True)
    print(f"   -> æµ‹è¯•é›†æ¸…æ´—æŽ‰ {len_test_before - len(df_test)} æ¡è„æ•°æ®")

    # --- 2. æž„å»ºè®­ç»ƒå­é›† ---
    # æ³¨æ„: KNNè®¡ç®—é‡å¤§ï¼Œæˆ‘ä»¬éœ€è¦é‡é‡‡æ ·
    print("\n[æ­¥éª¤1] æž„å»ºè®­ç»ƒå­é›†...")
    X_full = df_train_full[DEFENDER_SET]
    y_full = df_train_full['label']

    # åˆ’åˆ†éªŒè¯é›† (ä¿æŒçœŸå®žæ¯”ä¾‹ 100:1)
    X_train_pool, X_val_natural, y_train_pool, y_val_natural = train_test_split(
        X_full, y_full, test_size=0.2, random_state=2025, stratify=y_full
    )

    # è®­ç»ƒé›†é‡é‡‡æ ·
    df_pool = pd.concat([X_train_pool, y_train_pool], axis=1)
    df_bot = df_pool[df_pool['label'] == 1]
    df_benign = df_pool[df_pool['label'] == 0]

    n_bot = len(df_bot)
    # ðŸ”¥ ç­–ç•¥è°ƒæ•´: å°è¯• 1:1 é‡‡æ ·ä»¥æå‡ Recall (å¦‚æžœè¿˜æ˜¯ä½Žï¼Œè¿™é‡Œæ˜¯å…³é”®)
    # ä¸ºäº†å¯¹æ¯”ï¼Œè¿™é‡Œå…ˆä¿æŒä½ ä¹‹å‰çš„é€»è¾‘ï¼Œæˆ–è€…å»ºè®®æ”¹ä¸º n_bot * 1
    # --- ä¿®æ”¹ç‚¹ 1: å¢žåŠ è‰¯æ€§æ ·æœ¬æ¯”ä¾‹è‡³ 1:10 ---
    # ä¹‹å‰æ˜¯ n_bot * 5ï¼ŒçŽ°åœ¨æ”¹ä¸º * 10
    # ç›®çš„ï¼šè®©æ¨¡åž‹è§è¯†æ›´å¤šæ ·çš„è‰¯æ€§æ ·æœ¬ï¼Œå‡å°‘è¯¯æŠ¥
    n_benign_sample = int(n_bot * 20)

    df_benign_sampled = df_benign.sample(n=n_benign_sample, random_state=2025)
    df_train_balanced = pd.concat([df_bot, df_benign_sampled])

    print(f"   -> è®­ç»ƒæ ·æœ¬æ•°: {len(df_train_balanced)} (Bot: {n_bot}, Benign: {n_benign_sample})")

    # --- 3. ç¼©æ”¾ ---
    print("æ­£åœ¨ä½¿ç”¨Scalerè½¬æ¢æ•°æ®...")
    X_train_final = scaler.transform(df_train_balanced[DEFENDER_SET])
    y_train_final = df_train_balanced['label']
    X_val_natural_scaled = scaler.transform(X_val_natural)
    X_test_scaled = scaler.transform(df_test[DEFENDER_SET])
    y_test = df_test['label']

    # --- 4. è®­ç»ƒ ---
    print("\n[æ­¥éª¤2] è®­ç»ƒ KNN (High Precisionç‰ˆ)...")
    # --- ä¿®æ”¹ç‚¹ 2: å¢žåŠ  K å€¼åˆ° 51 ---
    # Kè¶Šå¤§ï¼Œå†³ç­–è¾¹ç•Œè¶Šå¹³æ»‘ï¼Œè¶Šä¸å®¹æ˜“è¯¯æŠ¥
    knn_model = KNeighborsClassifier(n_neighbors=31, weights='distance', n_jobs=-1)

    with tqdm(total=1, desc="KNN Fitting") as pbar:
        knn_model.fit(X_train_final, y_train_final)
        pbar.update(1)

    # --- 5. é˜ˆå€¼å¯»ä¼˜ ---
    print("\n[æ­¥éª¤3] åœ¨ã€çœŸå®žåˆ†å¸ƒéªŒè¯é›†ã€‘ä¸Šå¯»æ‰¾æœ€ä½³å†³ç­–é˜ˆå€¼...")
    val_probs = knn_model.predict_proba(X_val_natural_scaled)[:, 1]

    best_threshold = 0.5
    best_f1 = 0
    for thr in [0.1, 0.3, 0.5, 0.7, 0.9]:
        y_val_pred = (val_probs >= thr).astype(int)
        f1 = f1_score(y_val_natural, y_val_pred)
        if f1 > best_f1:
            best_f1 = f1
            best_threshold = thr

    print(f"âœ… æœ€ä½³é˜ˆå€¼: {best_threshold:.2f} (éªŒè¯é›† F1: {best_f1:.4f})")

    # --- 6. è¯„ä¼° ---
    joblib.dump(knn_model, HUNTER_MODEL_PATH)

    print(f"\n--- æœ€ç»ˆæŠ¥å‘Š (é˜ˆå€¼={best_threshold:.2f}) ---")
    test_probs = knn_model.predict_proba(X_test_scaled)[:, 1]
    y_pred = (test_probs >= best_threshold).astype(int)
    print(classification_report(y_test, y_pred, target_names=['Benign (0)', 'Bot (1)'], digits=4))


if __name__ == "__main__":
    main()