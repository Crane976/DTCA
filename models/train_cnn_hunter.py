# models/train_cnn_hunter.py (FINAL ROBUST VERSION)
import pandas as pd
import numpy as np
import os
import sys
import joblib
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler  # âœ… å¼•å…¥ Sampler
from sklearn.metrics import classification_report, f1_score
from sklearn.model_selection import train_test_split
from tqdm import tqdm

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path: sys.path.append(project_root)

from config import DEFENDER_SET, set_seed, LogMinMaxScaler  # å¼•å…¥è‡ªå®šä¹‰ Scaler
from models.cnn_architecture import CNN_Classifier
from models.mlp_architecture import FocalLoss

# --- Configuration ---
TRAIN_SET_PATH = os.path.join(project_root, 'data', 'splits', 'training_set.csv')
TEST_SET_PATH = os.path.join(project_root, 'data', 'splits', 'holdout_test_set.csv')
SCALER_PATH = os.path.join(project_root, 'models', 'global_scaler.pkl')
CNN_HUNTER_MODEL_PATH = os.path.join(project_root, 'models', 'cnn_hunter.pt')

FEATURE_DIM = len(DEFENDER_SET)
EPOCHS = 100
BATCH_SIZE = 256
VALIDATION_SPLIT = 0.2
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
RANDOM_SEED = 2025
BEST_PARAMS = {'learning_rate': 0.0005}


# âœ… å¤ç”¨ MLP çš„æ¸…æ´—é€»è¾‘
def clean_data(df, feature_cols):
    """ç»Ÿä¸€çš„æ•°æ®æ¸…æ´—å‡½æ•°: æ›¿æ¢Infå¹¶ä¸¢å¼ƒNaN"""
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(subset=feature_cols, inplace=True)
    return df


def main():
    set_seed(RANDOM_SEED)
    print("=" * 60)
    print("ğŸš€ å¼€å§‹è®­ç»ƒ 1D-CNN Hunter (ResNet-like, Balanced)...")
    print("=" * 60)
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # --- 1. åŠ è½½ä¸æ¸…æ´— ---
    print("\n[æ­¥éª¤1] æ­£åœ¨åŠ è½½æ•°æ®å’ŒScaler...")
    df_train_full = pd.read_csv(TRAIN_SET_PATH)
    df_test = pd.read_csv(TEST_SET_PATH)
    scaler = joblib.load(SCALER_PATH)
    feature_names = scaler.feature_names_in_

    print("   -> æ­£åœ¨æ¸…æ´—æ•°æ®...")
    df_train_full = clean_data(df_train_full, feature_names)
    df_test = clean_data(df_test, feature_names)

    # --- 2. è½¬æ¢ä¸åˆ’åˆ† ---
    X_train_full_scaled = scaler.transform(df_train_full[feature_names])
    y_train_full = df_train_full['label'].values

    X_test_scaled = scaler.transform(df_test[feature_names])
    y_test = df_test['label'].values

    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    X_train, X_val, y_train, y_val = train_test_split(
        X_train_full_scaled, y_train_full, test_size=VALIDATION_SPLIT, random_state=RANDOM_SEED, stratify=y_train_full
    )

    # --- 3. å‡è¡¡é‡‡æ ·å™¨ (å…³é”®!) ---
    print("\n[æ­¥éª¤2] é…ç½®å‡è¡¡é‡‡æ ·å™¨ (WeightedRandomSampler)...")
    class_sample_count = np.array([len(np.where(y_train == t)[0]) for t in np.unique(y_train)])
    weight = 1. / class_sample_count
    samples_weight = np.array([weight[t] for t in y_train.astype(int)])
    samples_weight = torch.from_numpy(samples_weight)

    sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))

    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                  torch.tensor(y_train, dtype=torch.float32).unsqueeze(1))

    # shuffle=False å› ä¸ºç”¨äº† sampler
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, shuffle=False)

    val_tensor_x = torch.tensor(X_val, dtype=torch.float32).to(device)
    val_tensor_y = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1).to(device)

    # --- 4. è®­ç»ƒ ---
    benign_ratio = (y_train_full == 0).sum() / len(y_train_full)
    model = CNN_Classifier(feature_dim=FEATURE_DIM).to(device)
    # æ—¢ç„¶ç”¨äº†å‡è¡¡é‡‡æ ·ï¼ŒFocal Loss çš„ alpha å¯ä»¥è®¾ä¸º 0.5 æˆ–è€…å¹²è„†ç”¨ CrossEntropy
    # è¿™é‡Œä¿æŒ Focal Loss ä»¥å¢å¼ºå¯¹éš¾æ ·æœ¬çš„æŒ–æ˜
    criterion = FocalLoss(alpha=0.5, gamma=2.0)
    optimizer = torch.optim.AdamW(model.parameters(), lr=BEST_PARAMS['learning_rate'])
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)

    print("\n[æ­¥éª¤3] å¼€å§‹è®­ç»ƒ...")
    best_val_loss = float('inf')

    for epoch in range(EPOCHS):
        model.train()
        # åŠ å…¥ tqdm æ˜¾ç¤ºè¿›åº¦
        pbar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{EPOCHS}", leave=False)
        for x_batch, y_batch in pbar:
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)
            logits = model(x_batch)
            loss = criterion(logits, y_batch)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})

        model.eval()
        with torch.no_grad():
            val_logits = model(val_tensor_x)
            val_loss = criterion(val_logits, val_tensor_y).item()

        scheduler.step(val_loss)
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), CNN_HUNTER_MODEL_PATH)

    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼Œæœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")

    # --- 5. é˜ˆå€¼å¯»ä¼˜ ---
    print("\n[æ­¥éª¤4] å¯»æ‰¾æœ€ä½³å†³ç­–é˜ˆå€¼...")
    final_model = CNN_Classifier(feature_dim=FEATURE_DIM).to(device)
    final_model.load_state_dict(torch.load(CNN_HUNTER_MODEL_PATH, map_location=device))
    final_model.eval()

    with torch.no_grad():
        val_probs = final_model.predict(val_tensor_x).cpu().numpy()

    best_threshold, best_f1 = 0.5, 0
    for threshold in np.arange(0.01, 1.0, 0.01):
        y_val_pred = (val_probs > threshold).astype(int)
        current_f1 = f1_score(y_val, y_val_pred, pos_label=1)
        if current_f1 > best_f1:
            best_f1, best_threshold = current_f1, threshold

    print(f"âœ… æœ€ä½³é˜ˆå€¼: {best_threshold:.2f} (F1: {best_f1:.4f})")

    # --- 6. æœ€ç»ˆè¯„ä¼° ---
    print("\n--- '1D-CNN Hunter'åœ¨ã€ç•™å‡ºæµ‹è¯•é›†ã€‘ä¸Šçš„çœŸå®æ€§èƒ½æŠ¥å‘Š ---")
    with torch.no_grad():
        test_tensor_x = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)
        test_probs = final_model.predict(test_tensor_x).cpu().numpy()
        y_pred = (test_probs > best_threshold).astype(int)
    print(classification_report(y_test, y_pred, target_names=['Benign (0)', 'Bot (1)'], digits=4))


if __name__ == "__main__":
    main()