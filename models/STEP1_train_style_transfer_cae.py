# models/STEP1_train_style_transfer_cae.py
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
import os
from config import UNIFIED_FEATURE_SET

# ==========================================================
# --- 1. é…ç½®åŒº ---
# ==========================================================
DATA_DIR = r'D:\DTCA\data\preprocessed'
MODELS_DIR = r'D:\DTCA\models'

# --- è¾“å…¥è·¯å¾„ ---
benign_processed_path = os.path.join(DATA_DIR, 'benign_traffic_processed.csv')
bot_processed_path = os.path.join(DATA_DIR, 'bot_traffic_processed.csv')

# --- è¾“å‡ºè·¯å¾„ ---
# è¿™æ˜¯æˆ‘ä»¬â€œé£Žæ ¼è¿ç§»â€å¼•æ“Žçš„æ ¸å¿ƒ
cae_model_path = os.path.join(MODELS_DIR, 'style_transfer_cae.pt')

# --- æ¨¡åž‹å‚æ•° ---
input_dim = len(UNIFIED_FEATURE_SET)
encoding_dim = 5
condition_dim = 2  # âœ… å…³é”®ï¼šçŽ°åœ¨æˆ‘ä»¬æœ‰ä¸¤ç±» (Benign, Bot)ï¼Œæ‰€ä»¥æ˜¯2ç»´
epochs = 100  # å¯ä»¥å¤šè®­ç»ƒä¸€ä¼šå„¿ï¼Œè®©æ¨¡åž‹å……åˆ†å­¦ä¹ 
batch_size = 128
lr = 0.001
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# --- æ¨¡åž‹å®šä¹‰ ---
class ConditionalAE(nn.Module):
    def __init__(self, input_dim, condition_dim, encoding_dim):
        super().__init__()
        # å¯ä»¥é€‚å½“åŠ æ·±ç½‘ç»œä»¥å­¦ä¹ æ›´å¤æ‚çš„æ˜ å°„
        self.encoder = nn.Sequential(
            nn.Linear(input_dim + condition_dim, 32), nn.ReLU(),
            nn.Linear(32, 16), nn.ReLU(),
            nn.Linear(16, encoding_dim)
        )
        self.decoder = nn.Sequential(
            nn.Linear(encoding_dim + condition_dim, 16), nn.ReLU(),
            nn.Linear(16, 32), nn.ReLU(),
            nn.Linear(32, input_dim)
        )

    def forward(self, x, c):
        x_cond = torch.cat([x, c], dim=1)
        encoded = self.encoder(x_cond)
        encoded_cond = torch.cat([encoded, c], dim=1)
        decoded = self.decoder(encoded_cond)
        return decoded, encoded


# ==========================================================
# --- 2. ä¸»è®­ç»ƒå‡½æ•° ---
# ==========================================================
def main():
    print("=============================================")
    print("ðŸš€ STEP 1: å¼€å§‹è®­ç»ƒ'é£Žæ ¼è¿ç§»'CAEå¼•æ“Ž...")
    print("=============================================")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # --- 1. åŠ è½½å¹¶åˆå¹¶æ•°æ® ---
    print("æ­£åœ¨åŠ è½½å¹¶å‡†å¤‡Benignå’ŒBotæ•°æ®...")
    try:
        df_benign = pd.read_csv(benign_processed_path)
        df_bot = pd.read_csv(bot_processed_path)
    except FileNotFoundError as e:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°é¢„å¤„ç†æ–‡ä»¶ - {e}");
        return

    # --- 2. åˆ›å»ºç‰¹å¾(X)å’Œæ¡ä»¶æ ‡ç­¾(C) ---
    X_benign = df_benign.values
    X_bot = df_bot.values

    # Benign: label 0 -> one-hot [1, 0]
    C_benign = np.zeros((len(X_benign), condition_dim))
    C_benign[:, 0] = 1

    # Bot: label 1 -> one-hot [0, 1]
    C_bot = np.zeros((len(X_bot), condition_dim))
    C_bot[:, 1] = 1

    # åˆå¹¶æ‰€æœ‰æ•°æ®
    X_full = np.concatenate([X_benign, X_bot], axis=0)
    C_full = np.concatenate([C_benign, C_bot], axis=0)

    # --- 3. åˆ’åˆ†æ•°æ®é›†å¹¶åˆ›å»ºDataLoader ---
    X_train, X_val, C_train, C_val = train_test_split(X_full, C_full, test_size=0.2, random_state=42,
                                                      stratify=C_full.argmax(axis=1))

    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                  torch.tensor(C_train, dtype=torch.float32))
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    val_tensor_x = torch.tensor(X_val, dtype=torch.float32).to(device)
    val_tensor_c = torch.tensor(C_val, dtype=torch.float32).to(device)

    # --- 4. åˆå§‹åŒ–æ¨¡åž‹å¹¶å¼€å§‹è®­ç»ƒ ---
    model = ConditionalAE(input_dim, condition_dim, encoding_dim).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.MSELoss()

    print("\nå¼€å§‹è®­ç»ƒCAEæ¨¡åž‹...")
    best_val_loss = float('inf')
    for epoch in range(epochs):
        model.train()
        for x_batch, c_batch in train_loader:
            x_batch, c_batch = x_batch.to(device), c_batch.to(device)
            recon, _ = model(x_batch, c_batch)
            loss = criterion(recon, x_batch)
            optimizer.zero_grad();
            loss.backward();
            optimizer.step()

        model.eval()
        with torch.no_grad():
            recon_val, _ = model(val_tensor_x, val_tensor_c)
            val_loss = criterion(recon_val, val_tensor_x).item()
            if (epoch + 1) % 10 == 0:
                print(f"  -> Epoch {epoch + 1:3d}/{epochs}, Val Loss: {val_loss:.6f}")

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), cae_model_path)

    print("\n--- è®­ç»ƒå®Œæˆ ---")
    print(f"è¡¨çŽ°æœ€å¥½çš„'é£Žæ ¼è¿ç§»'CAEå¼•æ“Žå·²ä¿å­˜åœ¨: {cae_model_path}")
    print(f"(Final Best Val Loss: {best_val_loss:.6f})")


if __name__ == "__main__":
    main()